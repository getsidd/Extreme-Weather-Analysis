<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url('https://themes.googleusercontent.com/fonts/css?kit=wAPX1HepqA24RkYW1AuHYA');ol.lst-kix_list_1-3{list-style-type:none}ol.lst-kix_list_1-4{list-style-type:none}ol.lst-kix_list_1-5{list-style-type:none}ol.lst-kix_list_1-6{list-style-type:none}ol.lst-kix_list_1-0{list-style-type:none}.lst-kix_list_1-4>li{counter-increment:lst-ctn-kix_list_1-4}ol.lst-kix_list_1-1{list-style-type:none}ol.lst-kix_list_1-2{list-style-type:none}ol.lst-kix_list_1-6.start{counter-reset:lst-ctn-kix_list_1-6 0}.lst-kix_list_1-1>li{counter-increment:lst-ctn-kix_list_1-1}ol.lst-kix_list_1-3.start{counter-reset:lst-ctn-kix_list_1-3 0}ol.lst-kix_list_1-2.start{counter-reset:lst-ctn-kix_list_1-2 0}ol.lst-kix_list_1-8.start{counter-reset:lst-ctn-kix_list_1-8 0}.lst-kix_list_1-0>li:before{content:"" counter(lst-ctn-kix_list_1-0,lower-latin) ") "}ol.lst-kix_list_1-5.start{counter-reset:lst-ctn-kix_list_1-5 0}ol.lst-kix_list_1-7{list-style-type:none}.lst-kix_list_1-1>li:before{content:"" counter(lst-ctn-kix_list_1-1,lower-latin) ". "}.lst-kix_list_1-2>li:before{content:"" counter(lst-ctn-kix_list_1-2,lower-roman) ". "}.lst-kix_list_1-7>li{counter-increment:lst-ctn-kix_list_1-7}ol.lst-kix_list_1-8{list-style-type:none}.lst-kix_list_1-3>li:before{content:"" counter(lst-ctn-kix_list_1-3,decimal) ". "}.lst-kix_list_1-4>li:before{content:"" counter(lst-ctn-kix_list_1-4,lower-latin) ". "}ol.lst-kix_list_1-0.start{counter-reset:lst-ctn-kix_list_1-0 0}.lst-kix_list_1-0>li{counter-increment:lst-ctn-kix_list_1-0}.lst-kix_list_1-6>li{counter-increment:lst-ctn-kix_list_1-6}.lst-kix_list_1-7>li:before{content:"" counter(lst-ctn-kix_list_1-7,lower-latin) ". "}.lst-kix_list_1-3>li{counter-increment:lst-ctn-kix_list_1-3}.lst-kix_list_1-5>li:before{content:"" counter(lst-ctn-kix_list_1-5,lower-roman) ". "}.lst-kix_list_1-6>li:before{content:"" counter(lst-ctn-kix_list_1-6,decimal) ". "}ol.lst-kix_list_1-7.start{counter-reset:lst-ctn-kix_list_1-7 0}.lst-kix_list_1-2>li{counter-increment:lst-ctn-kix_list_1-2}.lst-kix_list_1-5>li{counter-increment:lst-ctn-kix_list_1-5}.lst-kix_list_1-8>li{counter-increment:lst-ctn-kix_list_1-8}ol.lst-kix_list_1-4.start{counter-reset:lst-ctn-kix_list_1-4 0}.lst-kix_list_1-8>li:before{content:"" counter(lst-ctn-kix_list_1-8,lower-roman) ". "}ol.lst-kix_list_1-1.start{counter-reset:lst-ctn-kix_list_1-1 0}ol{margin:0;padding:0}.c3{border-right-style:solid;padding:0pt 5.8pt 0pt 5.8pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:93.5pt;border-top-color:#000000;border-bottom-style:solid}.c14{border-right-style:solid;padding:0pt 5.8pt 0pt 5.8pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:115.2pt;border-top-color:#000000;border-bottom-style:solid}.c0{color:#000000;font-weight:normal;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Calibri";font-style:normal}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left;direction:ltr}.c24{margin-left:36pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.0791666666666666}.c23{margin-left:36pt;padding-top:0pt;padding-left:0pt;padding-bottom:8pt;line-height:1.0791666666666666}.c19{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c17{margin-left:-5.8pt;border-collapse:collapse;margin-right:auto}.c5{orphans:2;widows:2;direction:ltr}.c4{font-size:14pt;font-weight:bold}.c12{margin-left:36pt;text-indent:36pt}.c20{padding:0;margin:0}.c21{font-family:"Calibri";font-weight:normal}.c18{color:#1155cc;text-decoration:underline}.c7{font-size:20pt;font-weight:bold}.c16{color:inherit;text-decoration:inherit}.c13{height:12pt}.c9{vertical-align:sub}.c6{height:11pt}.c22{height:13pt}.c10{font-weight:bold}.c15{font-size:26pt}.c11{text-align:center}.c25{vertical-align:super}.c2{font-size:12pt}.c8{height:0pt}.title{padding-top:24pt;color:#000000;font-weight:bold;font-size:36pt;padding-bottom:6pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.0791666666666666;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Calibri"}p{margin:0;color:#000000;font-size:11pt;font-family:"Calibri"}h1{padding-top:24pt;color:#000000;font-weight:bold;font-size:24pt;padding-bottom:6pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:bold;font-size:18pt;padding-bottom:4pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:bold;font-size:14pt;padding-bottom:4pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:bold;font-size:12pt;padding-bottom:2pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:bold;font-size:11pt;padding-bottom:2pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:bold;font-size:10pt;padding-bottom:2pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c19"><p class="c5 c12"><span class="c10 c15">EXTREME WEATHER ANALYSIS</span></p><p class="c5 c12"><span class="c10 c15">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(CSE 603)</span></p><p class="c5 c12"><span class="c10 c15">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c7">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c5 c12 c6 c11"><span class="c7"></span></p><p class="c5 c11"><span class="c7">Under the Guidance of</span></p><p class="c5 c12"><span class="c7">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Dr. Jaroslaw Zola</span></p><p class="c5 c12 c6 c11"><span class="c7"></span></p><p class="c5 c12 c6"><span class="c7"></span></p><p class="c5 c12 c6"><span class="c7"></span></p><p class="c5 c12 c6"><span class="c7"></span></p><p class="c5 c12 c6"><span class="c7"></span></p><p class="c5 c6 c12"><span class="c7"></span></p><p class="c5 c12 c6"><span class="c7"></span></p><p class="c5 c12"><span class="c7">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c5 c12"><span class="c7">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Surya Siddharth Pemmaraju</span></p><p class="c5 c12"><span class="c7">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;50135193</span></p><p class="c5 c12"><span class="c7">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sri Rajarsh Vylta</span></p><p class="c5 c12"><span class="c7">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;50134707</span></p><p class="c5"><span class="c4">Introduction:</span></p><p class="c5"><span class="c2">Timely, Accurate and reliable weather warnings are essential as they give us time to protect life and property. Extreme weather conditions include heat waves, tornadoes, hurricanes, hail storms, heavy fog, heavy precipitation etc. We plan to analyze the weather data and predict extreme weather conditions based on the history of similar conditions. Basically, we preprocess the data that we collected from the National Climatic Data Center, filter out unnecessary fields and train the filtered data using a machine learning algorithms to generate a model. Once the model is generated, we can use this model to predict extreme weather conditions based on the parameters that we selected. We also find the accuracy of the trained model using test data.</span></p><p class="c5"><span class="c2">We plan to use Apache Spark for the processing of the data as the climate dataset is very large and lots of rows will be used in computing the machine learning model. </span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5"><span class="c4">The Data Set:</span></p><p class="c5"><span class="c2">The data set was obtained from the National Climatic Data Center &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(NCDC) which preserves and monitors the historical weather data and information. We collected the weather data for various cities viz Chicago, Milwaukee, Albany, Binghamton, Boston, DC, Detroit, Kingston, New York City, Niagara Falls and Philadelphia from January 1</span><span class="c2 c25">st</span><span class="c2">&nbsp;1950 to October 1</span><span class="c25 c2">st</span><span class="c2">&nbsp;2015. The size of the data was close to 1GB. The parameters of the data set included Precipitation (mm), Snow (mm), Snow Depth(mm), Sunshine (Daily Total minutes), Maximum Temperature (Celsius), Minimum Temperature (Celsius), Average Wind Speed (m/s). The Extreme Weather Types are: Heavy Fog, Freezing Fog, Thunder, Ice Pellets, Hail Storm, Glaze Ice, Volcanic Ash, Tornado and Drifting snow. </span></p><p class="c5"><span class="c2">The weather types are either 0 or 1 which correspond to the weather type being absent or present on that day. So if there is at least one of the above mentioned weather types present on a particular day, then we mark that day as having extreme weather. </span></p><p class="c5"><span class="c2"><br></span><span class="c4">Pre Processing:</span></p><p class="c5"><span class="c2">For pre-processing the weather data, we first selected the parameters that affect the extreme weather the most. These are the amount of Precipitation on that day, the amount of snowfall, the depth of snow, Maximum temperature and Minimum Temperature. We have selected these 5 parameters as they are the core values that affect extreme weather. We also added an extra column called as Extreme which is set to either 1 or 0 depending on whether at least one of the aforementioned weather types being 1 or none of the values being 1. This column will be used as the Label column while using the machine learning algorithm. </span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5"><span class="c2">The main difficulty that we faced while pre-processing the data is that there were a lot of missing data for the parameters in the data set that we used because the availability of climatic measurements varies spatially and temporally. One of the approach to circumvent this problem is to completely ignore the rows that have missing values in the parameters of interest. But this would mean that we would be only making the predictions on a subset of the original data and also the accuracy of the model will decrease. </span></p><p class="c5"><span class="c2">Hence we used an approach called imputation which is the process of replacing missing values with substituted values. We have assumed that for a particular station, in a month the parameters would be more or less similar. So, for each parameter we take the average of each month excluding the missing values and replace the missing values with the averages. &nbsp;This helped us to consider the entire dataset and just not a subset of it. </span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5"><span class="c4">Selection of Algorithm:</span></p><p class="c5"><span class="c2">We plan to predict extreme weather conditions based on climatic parameters such as precipitation, snow, temperature etc. Hence we decided to use machine learning for the prediction.</span></p><p class="c5"><span class="c2">Machine learning algorithms can be broadly classified into two types </span></p><ol class="c20 lst-kix_list_1-0 start" start="1"><li class="c5 c24"><span class="c21 c2">Clustering algorithms</span></li><li class="c5 c23"><span class="c2 c21">Classification and Regression </span></li></ol><p class="c5"><span class="c2">Clustering is primarily used for cases where the data is unlabeled and has to be divided into similar classes. In our problem we have pre-defined labels for the respective features. We need to classify a new instance of features into one or the other class. Hence we decided to use Classification and Regression algorithms.</span></p><p class="c5"><span class="c2">In Spark&rsquo;s MLlib library the two linear classification and regression algorithms are Linear SVM and Logistic Regression. Other algorithms like Na&iuml;ve Bayes, Decision tress are used for multiclass classification. As we only have two classes to classify our data into we did not consider these algorithms. </span></p><p class="c5"><span class="c2">Initially we used Logistic Regression for generating the regression model. We also tried Linear SVM (Support Vector Machines) for doing the same. We found out that even though it takes longer for SVM to train the model, the accuracy got from this algorithm is superior to that of Logistic Regression. Therefore we decided to use Linear SVM for generating the model.</span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5"><span class="c4">Methodology:</span></p><p class="c5"><span class="c2">In the pre-process stage we filtered the large data set by removing unnecessary parameters. The five core parameters that we considered are Precipitation, Snowfall, Snow Depth, Maximum Temperature and Minimum Temperature. These are the features for the machine learning algorithm. Based on the values of the Weather Types we generated an Extreme column as described in the pre-processing section. &nbsp;This column was used as the Label. </span></p><p class="c5"><span class="c2">For filling in the missing data we considered Station Name and Date columns of the data as well because we calculated the averages of the values based on the station name and the month.</span></p><p class="c5"><span class="c2">We concatenated Station name, year and month to form a unique key which was then used in the reduceByKey transformation of Spark. We then calculated the averages of each month in a station and filled the missing values with the averages.</span></p><p class="c5"><span class="c2">For example a sample key would look like Alcovedamnyus195101 and when we use the reduceByKey operation we would get all the values for the station alcove dam in New York for the year 1951 in the month of January.</span></p><p class="c5"><span class="c2">The training data set has to be represented by an RDD of LabeledPoint in MLlib for generating the model. So we converted the RDD into a LabeledPoint RDD with Label and the features and fed the RDD to SVM algorithm.</span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5"><span class="c4">Experiment 1:</span></p><p class="c5"><span class="c2">The initial approach that we considered was to ignore the rows that had missing values. So the data set from 2.6 million rows came down to 1 million rows. We used the SVM algorithm on this dataset and calculated the error. The error value was 0.1755. </span></p><p class="c5"><span class="c2">To find the sweet spot for the number of executor cores that are to be used for our experiments we varied the execution cores from 1 to 6. We found out that for 4 execution cores we are getting maximum efficiency and if we increased the number of cores beyond that the efficiency remained more or less constant.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><a href="#" name="57f26555cbed82ad5f4f06ffa0e35d3ab286ee8e"></a><a href="#" name="0"></a><table cellpadding="0" cellspacing="0" class="c17"><tbody><tr class="c13"><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">Number of Nodes</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">No. of Tasks/Node</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">Execution cores</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">Time taken (in secs)</span></p></td></tr><tr class="c13"><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">62.59</span></p></td></tr><tr class="c22"><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">2</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">57.47</span></p></td></tr><tr class="c13"><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">3</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">53.96</span></p></td></tr><tr class="c13"><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">51.77</span></p></td></tr><tr class="c13"><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">5</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">52.71</span></p></td></tr><tr class="c13"><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">6</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c1"><span class="c0">51.88</span></p></td></tr></tbody></table><p class="c5 c6"><span class="c2"></span></p><p class="c5"><span class="c2">Hence we used 4 execution cores for the rest of the experiments.</span></p><p class="c5"><span class="c2">We have considered the following configuration as the base configuration for our experiments (T</span><span class="c2 c9">1</span><span class="c2">):</span></p><p class="c5"><span class="c2">Number of nodes = 1</span></p><p class="c5"><span class="c2">Number of Tasks/Node = 1</span></p><p class="c5"><span class="c2">Number of Executor Cores = 4</span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5"><span class="c2">&nbsp; The results of experiment 1 are the following:</span></p><a href="#" name="680c54ac617636a9162218ee57adc466a3b1da59"></a><a href="#" name="1"></a><table cellpadding="0" cellspacing="0" class="c17"><tbody><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Number of Nodes</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Number of Tasks/Node</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Executor cores</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Time taken (in secs)</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Efficiency (%)</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">103.43</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">100</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">2</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">74.97</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">68.98</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">3</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">65.46</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">52.66</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">57.12</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">45.26</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">8</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">57.16</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">22.61</span></p></td></tr></tbody></table><p class="c5 c6"><span class="c2"></span></p><p class="c5"><span class="c10 c2">Conclusions:</span></p><p class="c5"><span class="c2">The conclusions that can be drawn from this experiment are that for the problem as we increase the number of nodes the time decreases till 4 nodes and stays the same after that. We can say that for the algorithm, the data size of 1 GB is not sufficient to show the scalability that is desired.</span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5"><span class="c4">Experiment 2:</span></p><p class="c5"><span class="c2">Next we considered imputation to fill in the missing values. So we were able to use all of the 2.6 million rows of the data set. As we have more accurate data the error decreased from 0.1755 to 0.116.</span></p><p class="c5"><span class="c2">The results of experiment 2 are as follows:</span></p><a href="#" name="7636ff9beaaedbad8d0c15b6bf758efb4b9be7f8"></a><a href="#" name="2"></a><table cellpadding="0" cellspacing="0" class="c17"><tbody><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Number of Nodes</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Number of Tasks/Node</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Executor cores</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Time taken (in secs)</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Efficiency (%)</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">321.94</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">100</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">2</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">208.67</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">77.14</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">3</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">192.44</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">55.76</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">149.16</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">53.95</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">8</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">100.03</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">40.23</span></p></td></tr></tbody></table><p class="c5 c6"><span class="c2"></span></p><p class="c5"><span class="c2">Then we tried caching the data to improve the performance. </span></p><p class="c5"><span class="c2">The results that we got after caching are as follows:</span></p><a href="#" name="939b306e06252766b76a76605a7adfe8591937bb"></a><a href="#" name="3"></a><table cellpadding="0" cellspacing="0" class="c17"><tbody><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Number of Nodes</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Number of Tasks/Node</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Executor cores</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Time taken (in secs)</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">234.79</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">2</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">137.46</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">3</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">125.33</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">96.55</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">8</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">94.58</span></p></td></tr></tbody></table><p class="c5 c6"><span class="c2"></span></p><p class="c5 c6"><span class="c10 c2"></span></p><p class="c5 c6"><span class="c10 c2"></span></p><p class="c5"><span class="c10 c2">Conclusions:</span></p><p class="c5"><span class="c2">From this experiment we can say that our imputation was successful as the error decreased</span><span class="c10 c2">&nbsp;</span><span class="c2">from 0.1755 to 0.116. When we cached the data into the memory we observed significant decrease in the time taken. Also we can see that the efficiency of the algorithm has increased. But still as the data size is 1GB, it is not sufficient to show the scalability desired.</span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5"><span class="c4">Experiment 3:</span></p><p class="c5"><span class="c2">In this experiment we decided to double the data to increase the scalability of the algorithm. </span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5"><span class="c2">The results of the experiment are the following:</span></p><a href="#" name="20ac3ceb247108b239a9fa08933819617fc00756"></a><a href="#" name="4"></a><table cellpadding="0" cellspacing="0" class="c17"><tbody><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Number of Nodes</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Number of Tasks/Node</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Executor cores</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Time taken (in secs)</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Efficiency (%)</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">461.34</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">100</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">2</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">227.9</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">101.21</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">3</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">179.66</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">85.59</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">141.99</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">81.22</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">8</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">102.57</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">56.22</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">16</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">99</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">29.125</span></p></td></tr></tbody></table><p class="c5 c6"><span class="c2"></span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 600.00px; height: 371.00px;"><img alt="" src="images/image01.png" style="width: 600.00px; height: 371.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c2">Fig 1: This figure shows the variation of efficiency with the number of nodes.</span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5"><span class="c10 c2">Conclusions:</span></p><p class="c5"><a name="h.s6jesd48ilyy"></a><span class="c2">From this experiment we can see that by increasing the size of the data we were able to increase the efficiency of the algorithm. Also for 2 nodes we can see superlinear speed up. This can be explained as follows: By default the executor memory is 1GB. As we have doubled the data, the data size would be 2GB. We have a total of 2 executors with 2GB memory. Hence it will be able to cache maximum amount of data into cache and we get superlinear speedup.</span></p><p class="c5 c6"><a name="h.jjmrb5ggiu35"></a></p><p class="c5"><span class="c4">Experiment 4:</span></p><p class="c5"><a name="h.wjcfwtz9lgp6"></a><span class="c2">From the previous experiment we can see that even though the scalability increased till 8 nodes, we need more scalability for 16 nodes. This is due to the size of the small size of the data set. Hence we considered tripling the data.</span></p><p class="c5"><a name="h.s6jesd48ilyy"></a><span class="c2">When we tripled the data set, the total size of the data set was 3GB. &nbsp;The results of the experiment are the following:</span></p><p class="c5 c6"><a name="h.s6jesd48ilyy"></a></p><p class="c5 c6"><span class="c2"></span></p><a href="#" name="d0d76bab5c9a50e4c35a4d287dfb1baa06f6805e"></a><a href="#" name="5"></a><table cellpadding="0" cellspacing="0" class="c17"><tbody><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Number of Nodes</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Number of Tasks/Node</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Executor cores</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Time taken (in secs)</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Efficiency (%)</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">750</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">100</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">2</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">406.71</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">92.20</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">3</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">227.83</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">109.73</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">187.76</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">99.86</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">8</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">142.15</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">65.95</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">12</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">103.89</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">60.15</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">16</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">110</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">42.61</span></p></td></tr></tbody></table><p class="c5 c6"><span class="c4"></span></p><p class="c5"><a name="h.9r80m05908lk"></a><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 600.00px; height: 371.00px;"><img alt="" src="images/image00.png" style="width: 600.00px; height: 371.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><a name="h.1g0longg557l"></a><span class="c2">Fig 2: This figure shows the variation of Experiment time with Expected time as we vary the number of nodes.</span></p><p class="c5"><a name="h.1g0longg557l"></a><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 600.00px; height: 371.00px;"><img alt="" src="images/image04.png" style="width: 600.00px; height: 371.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><a name="h.l20xakm4m1bu"></a><span class="c2">Fig 3: This figure shows the variation of experiment speedup compared to the linear speedup when the number of nodes are increased</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 563.50px; height: 348.79px;"><img alt="" src="images/image03.png" style="width: 563.50px; height: 348.79px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><a name="h.9dfmlom1xua2"></a><span class="c2">Fig 4: This figure shows efficiency of the algorithm with increase in the number of nodes.</span></p><p class="c5 c6"><a name="h.9muw8hjudodg"></a></p><p class="c5"><span class="c10 c2">Conclusions:</span></p><p class="c5"><a name="h.1ktmmvu8mblr"></a><span class="c2">From this experiment we can conclude that by tripling the size of the data we were able to increase the efficiency of the algorithm with 16 nodes to 42%. Also for 3 nodes we can see superlinear speed up. This can be explained in a similar way as the previous experiment. Total Size of data set 3GB and total executor memory is 3G. Hence the speedup.</span></p><p class="c5 c6"><a name="h.s6jesd48ilyy"></a></p><p class="c5"><span class="c4">Experiment 5:</span></p><p class="c5"><a name="h.t9k6y6svmiwy"></a><span class="c2">Next we tried optimizing the memory of the executors. We did experiments by giving each executors memory of 2GB and 4GB.</span></p><p class="c5"><a name="h.gyqk5wf9q38m"></a><span class="c2">The results of the experiments are the following: </span></p><p class="c5 c6"><a name="h.1ktmmvu8mblr"></a></p><p class="c5 c6"><span class="c2"></span></p><a href="#" name="9d0715f5b79609000d02535825923137746dff79"></a><a href="#" name="6"></a><table cellpadding="0" cellspacing="0" class="c17"><tbody><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Number of Nodes</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Number of Tasks/Node</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Executor cores</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Time taken (in secs)</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">531.12</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">2</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">300.57</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">3</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">228.73</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">185.35</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">8</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">133.73</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">16</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">112.6</span></p></td></tr></tbody></table><p class="c5 c6"><span class="c2"></span></p><p class="c5"><span class="c2">This table shows the time taken for the program with executor memory = 2GB</span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5 c6"><span class="c2"></span></p><a href="#" name="a4be24dbf6efb9eb66e8a02dbf873a83735abc4d"></a><a href="#" name="7"></a><table cellpadding="0" cellspacing="0" class="c17"><tbody><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Number of Nodes</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Number of Tasks/Node</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Executor cores</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Time taken (in secs)</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">531.61</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">2</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">302.78</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">3</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">226.4</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">186.64</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">8</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">136.55</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">16</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">113.74</span></p></td></tr></tbody></table><p class="c5 c6"><span class="c2"></span></p><p class="c5"><span class="c2">This table shows the time taken for the program with executor memory = 4GB</span></p><p class="c5"><span class="c10 c2">Conclusions:</span></p><p class="c5"><a name="h.ty667dw069jw"></a><span class="c2">The size of dataset is 3GB. When we considered the executor memory of 2GB we observed that for 1 node and 2 nodes the time taken has reduced. This is because the total memory of the executors in each case is 2GB and 4GB. Hence it was able to utilize the caching effectively.</span></p><p class="c5"><a name="h.36x86mjzcgi0"></a><span class="c2">But as we increased the number of nodes to 3,4,8,16 the total memory was 6GB,8GB,16GB and 32GB. &nbsp;Running executors with too much memory often results in excessive garbage collection delays and hence the time does not decrease.</span></p><p class="c5 c6"><span class="c4"></span></p><p class="c5 c6"><span class="c4"></span></p><p class="c5"><span class="c4">Experiment 6:</span></p><p class="c5"><a name="h.739alsexeit2"></a><span class="c2">The final experiment was done by quadrupling the data set. </span></p><p class="c5"><a name="h.dnb8b1ij4zua"></a><span class="c2">The results of the experiment are as follows:</span></p><p class="c5 c6"><span class="c2"></span></p><a href="#" name="d9e8e2875785f20cb5c1d34d4d090e356afa0332"></a><a href="#" name="8"></a><table cellpadding="0" cellspacing="0" class="c17"><tbody><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Number of Nodes</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Number of Tasks/Node</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Executor cores</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Time taken (in secs)</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">Efficiency (%)</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1082.5</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">100</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">2</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">934.89</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">57.89</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">3</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">384.85</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">93.75</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">233.02</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">116.13</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">8</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">149.98</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">90.22</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">12</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">137.81</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">65.45</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">16</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">109.19</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">61.96</span></p></td></tr><tr class="c8"><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">32</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">1</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">4</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">105.52</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c1"><span class="c0">32.05</span></p></td></tr></tbody></table><p class="c5 c6"><span class="c2"></span></p><p class="c5 c6"><a name="h.1ktmmvu8mblr"></a></p><p class="c5 c6"><span class="c2"></span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 600.00px; height: 371.00px;"><img alt="" src="images/image02.png" style="width: 600.00px; height: 371.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c2">Fig 5: This graph shows the efficiency of the algorithm with number of nodes.</span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5"><span class="c2 c10">Conclusions:</span></p><p class="c5"><a name="h.2h3bozmrhh0c"></a><span class="c2">By quadrupling the size of the data set we were able to increase the efficiency of 16 nodes to about 62%. The time taken for 32 nodes to complete the job is just 4 seconds less than that of 16 nodes. Hence we are not able to get very good efficiency for 32 nodes. The overhead caused by using 32 nodes is restricting the efficiency.</span></p><p class="c5 c6"><a name="h.cna74xsjssft"></a></p><p class="c5"><span class="c4">Failed Experiments:</span></p><p class="c5"><a name="h.hu0qxlh80itx"></a><span class="c10 c2">Using Kyro Serializer:</span></p><p class="c5"><a name="h.r4hpi2xrk85p"></a><span class="c2">Kryo is a serialization framework. Serialization plays an important role in the performance of the application. Kryo serializes objects more quickly when compared to Java serializer. When we made our program to use Kryo serializer, we did not see a significant improvement in the performance.</span></p><p class="c5 c6"><a name="h.yp66gw9vi71y"></a></p><p class="c5 c6"><a name="h.sang894ccwhq"></a></p><p class="c5 c6"><a name="h.grd0e7o65399"></a></p><p class="c5"><a name="h.yk4pzzp0n4w5"></a><span class="c10 c2">Number of Partition</span><span class="c2">s: </span></p><p class="c5"><a name="h.xpy8dife2p5"></a><span class="c2">If the number of partitions is too low we won&rsquo;t be taking full advantage of all the CPU available. So we checked the number of partitions for the parent RDD of the RDD in which reduceByKey transformation occurs. This was 96. So, we increased &nbsp;the number of partitions by multiplying the parent RDD size with 1.5 and checked the performance. Also, we tried to decrease the number of partitions using coalesce transformation. But the performance was more or less same. This maybe attributed to the RDD having optimal number of partitions by default for this problem. </span></p><p class="c5 c6"><a name="h.j35wqzi125o3"></a></p><p class="c5 c6"><a name="h.yp66gw9vi71y"></a></p><p class="c5 c6"><a name="h.40fqlj4t5by8"></a></p><p class="c5"><span class="c4">References:</span></p><p class="c5"><a name="h.io7brpxo81dr"></a><span class="c2">1)</span><span class="c18 c2"><a class="c16" href="https://www.google.com/url?q=http://spark.apache.org/docs/latest/programming-guide.html&amp;sa=D&amp;usg=AFQjCNHoTVXoj7KHKvoO7F0DZfQDMoIz5g">http://spark.apache.org/docs/latest/programming-guide.html</a></span></p><p class="c5"><a name="h.eiyoh5f0cmx1"></a><span class="c2">2)</span><span class="c18 c2"><a class="c16" href="https://www.google.com/url?q=https://ogirardot.wordpress.com/2015/01/09/changing-sparks-default-java-serialization-to-kryo/&amp;sa=D&amp;usg=AFQjCNFN7UaXRLEKd-Vh-ME9zOyAw8NXtw">https://ogirardot.wordpress.com/2015/01/09/changing-sparks-default-java-serialization-to-kryo/</a></span></p><p class="c5"><a name="h.ac3j36stxj2q"></a><span class="c2">3) </span><span class="c2 c18"><a class="c16" href="https://www.google.com/url?q=http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/&amp;sa=D&amp;usg=AFQjCNH0vRRy_rJVC8eXJdP-c_zZPJ0vhA">http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/</a></span></p><p class="c5"><a name="h.2h3bozmrhh0c"></a><span class="c2">4) Learning Spark by Holden Karau, Andy Konwinski, Patrick Wendell &amp; Matei Zaharia</span></p><p class="c5 c6"><a name="h.ox1kku12ois3"></a></p><p class="c5 c6"><a name="h.36x86mjzcgi0"></a></p><p class="c5 c6"><span class="c2"></span></p><p class="c5 c6"><span class="c2"></span></p><p class="c5 c6"><span class="c2"></span></p></body></html>